library(tidyverse)
library(lubridate)
library(broom)
library(forecast)
library(jsonlite)

# FunÃ§Ã£o para anÃ¡lise descritiva
descriptive_analysis <- function(df) {
  cat(" ANÃLISE DESCRITIVA ")
  
  # EstatÃ­sticas sumÃ¡rias
  summary_stats <- df %>%
    group_by(product_id, category) %>%
    summarise(
      total_sales = sum(sales),
      avg_sales = mean(sales),
      sd_sales = sd(sales),
      total_customers = sum(customers),
      .groups = 'drop'
    )
  
  # Teste ANOVA entre categorias
  anova_test <- aov(sales ~ category, data = df)
  anova_summary <- tidy(anova_test)
  
  # CorrelaÃ§Ã£o
  correlation <- cor(df$sales, df$customers)
  
  # Retornar resultados
  list(
    summary_stats = summary_stats,
    anova_pvalue = anova_summary$p.value[1],
    correlation = correlation,
    total_categories = n_distinct(df$category)
  )
}

# FunÃ§Ã£o para anÃ¡lise temporal
time_series_analysis <- function(df) {
  cat(" ANÃLISE DE SÃ‰RIES TEMPORAIS ")
  
  # Agregar por data
  daily_sales <- df %>%
    group_by(date) %>%
    summarise(daily_sales = sum(sales), .groups = 'drop')
  
  # Converter para sÃ©rie temporal
  ts_data <- ts(daily_sales$daily_sales, frequency = 7)
  
  # DecomposiÃ§Ã£o
  decomposition <- stl(ts_data, s.window = "periodic")
  
  # Modelo de forecast
  forecast_model <- auto.arima(ts_data)
  future_forecast <- forecast(forecast_model, h = 30)
  
  list(
    decomposition = decomposition,
    forecast = future_forecast,
    model_summary = summary(forecast_model)
  )
}

# FunÃ§Ã£o para anÃ¡lise de regiÃµes
regional_analysis <- function(df) {
  cat("=== ANÃLISE REGIONAL ===\n")
  
  regional_stats <- df %>%
    group_by(region) %>%
    summarise(
      total_sales = sum(sales),
      market_share = total_sales / sum(df$sales),
      avg_customers = mean(customers),
      .groups = 'drop'
    )
  
  # Teste chi-quadrado para distribuiÃ§Ã£o de produtos por regiÃ£o
  chi_test <- chisq.test(table(df$region, df$product_id))
  
  list(
    regional_stats = regional_stats,
    chi_square_pvalue = chi_test$p.value
  )
}

# Pipeline principal
main_analysis <- function() {
  # Ler dados do Python
  df <- read_csv("data/processed_sales.csv") %>%
    mutate(date = ymd(date))
  
  cat("ğŸ“Š Iniciando anÃ¡lise")
  cat("ğŸ“ˆ Total de registros:", nrow(df), "\n")
  
  # Executar anÃ¡lises
  desc_analysis <- descriptive_analysis(df)
  ts_analysis <- time_series_analysis(df)
  reg_analysis <- regional_analysis(df)
  
  # Salvar resultados para Python
  results <- list(
    descriptive = desc_analysis,
    time_series = list(
      forecast_mean = as.numeric(ts_analysis$forecast$mean),
      forecast_lower = as.numeric(ts_analysis$forecast$lower[,2]),
      forecast_upper = as.numeric(ts_analysis$forecast$upper[,2])
    ),
    regional = reg_analysis,
    metadata = list(
      analysis_date = Sys.time(),
      records_processed = nrow(df)
    )
  )
  
  # Salvar resultados em JSON
  write_json(results, "data/r_analysis_results.json", pretty = TRUE)
  
  cat("âœ… AnÃ¡lise R concluÃ­da! Resultados salvos em JSON.\n")
  
  return(results)
}

# Executar anÃ¡lise
if (interactive()) {
  analysis_results <- main_analysis()
}